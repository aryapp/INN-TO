{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQlCQ0he0WY2",
    "outputId": "61baa2ac-cfd3-472c-e4c5-80877d4c3e7b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9tuIxx70WY9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from tkinter import Tcl\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uk5soK8s0WY-",
    "outputId": "41623088-c3ed-482e-f8f1-e06b2f824087",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.plot_samples import save_samples\n",
    "\n",
    "\n",
    "project_path = Path().cwd().parent / \"two_dim\"  \n",
    "os.chdir(Path.cwd().parent\n",
    "\n",
    "from two_dim.args import args, device\n",
    "from two_dim.train import train, test, init_networks\n",
    "from two_dim.utils.load_data import load_data\n",
    "from two_dim.utils.load_data_v7_6 import load_data_v7_6\n",
    "\n",
    "results_dir = str(project_path / \"results\")\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5ynHoaI0WZK",
    "outputId": "73e3ff2e-7fe5-4fb9-8a6f-495097644275",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_type = \"synthetic\"\n",
    "ntrain = 6000\n",
    "input_size = 64\n",
    "output_size = 64\n",
    "\n",
    "\n",
    "Train_hdf5_file = 'E:\\\\INN-TO\\\\X_y_8580_all_iter_new.hdf5'\n",
    "with h5py.File(Train_hdf5_file, 'r') as f:\n",
    "    print(len(f['x_train_all']))\n",
    "    x_train = f['x_train_all'][:ntrain]\n",
    "    y_train = f['y_train_all'][:ntrain][:,[0,3,6,9],:,:]\n",
    "    x_test = f['x_test_all'][:int(ntrain/3)]\n",
    "    y_test = f['y_test_all'][:int(ntrain/3)][:,[0,3,6,9],:,:]\n",
    "    print('x_train:',x_train.shape)\n",
    "    print('y_train:',y_train.shape)\n",
    "    print('x_test:',x_test.shape)\n",
    "    print('y_test:',y_test.shape)\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(TensorDataset(torch.FloatTensor(x_train),torch.FloatTensor(y_train)), batch_size=16, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(TensorDataset(torch.FloatTensor(x_test),torch.FloatTensor(y_test)),batch_size=16, shuffle=False, drop_last=True)\n",
    "# sample_loader = DataLoader(TensorDataset(torch.FloatTensor(x_test),torch.FloatTensor(y_test)),batch_size=1, shuffle=False, drop_last=True)\n",
    "\n",
    "INN_network, cond_network, device, optimizer = init_networks(args, device, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Path.cwd())\n",
    "if os.path.exists( Path.cwd().parent.parent / \"Data\"):\n",
    "    Sample_hdf5_file = Path.cwd().parent.parent / \"Data\"/ \"sample_xy_OOD_vfrac.hdf5\"\n",
    "else:\n",
    "    print(\"Error in sample file finding out\")\n",
    "        \n",
    "n_sa= 1    \n",
    "with h5py.File(Sample_hdf5_file, 'r') as s:\n",
    "    sa_x = s['sa_x'][:n_sa]\n",
    "    sa_y = s['sa_y'][:n_sa][:,[0,3,6,9],:,:]\n",
    "\n",
    "sample_loader = DataLoader(TensorDataset(torch.FloatTensor(sa_x),torch.FloatTensor(sa_y)),batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(sa2[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtOvTDYt0WZc"
   },
   "outputs": [],
   "source": [
    "def sample_data_new(epoch, loader, INN_network, cond_network, device, n_samples, save_y=False):\n",
    "    INN_network.eval()\n",
    "    cond_network.eval()\n",
    "    input_all, target_all = next(iter(loader))\n",
    "    sa_gen = 1\n",
    "    generated_x_all = np.zeros((12,64,64))\n",
    "    for i in range(sa_gen):\n",
    "        input = input_all[i]\n",
    "        target = target_all[i].reshape(1,4,input_size,input_size)\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        x = input.view(1, 1, 64, 64)\n",
    "        if len(target.shape) != 4:\n",
    "            target = target.view(1, 4, 64)\n",
    "\n",
    "        target = target[0, :, :]\n",
    "        target = target.cpu().data.numpy()\n",
    "        l = np.repeat(np.array(target)[np.newaxis, :, :], n_samples, axis=0)\n",
    "        l = torch.Tensor(l).to(device)\n",
    "        z = torch.randn(n_samples, 4096).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y1 = cond_network(l)\n",
    "            input = x.view(1, 4096)\n",
    "    #         c = y1[2]\n",
    "    #         c2 = y1[1]\n",
    "    #         c3 = y1[0]\n",
    "    #         c4 = y1[3]\n",
    "            c = y1[0]\n",
    "            c2 = y1[1]\n",
    "            c3 = y1[2]\n",
    "            c4 = y1[3]\n",
    "            generated_x = INN_network(z, c, c2, c3, c4, forward=False)\n",
    "        generated_x = generated_x.cpu().data.numpy()\n",
    "        #generated_x = torch.sigmoid(generated_x)\n",
    "        input_test = input[0, :].cpu().data.numpy()\n",
    "        input1 = input_test.reshape(1, 1, 64, 64)\n",
    "        mean_samples1 = np.mean(generated_x, axis=0)\n",
    "        mean_samples1 = mean_samples1.reshape(1, 1, 64, 64)\n",
    "        generated_x = generated_x[:2, :, :, :]\n",
    "        x1 = np.concatenate((input1, mean_samples1, generated_x), axis=0)\n",
    "        generated_x_all[i,:,:] = generated_x[0][0]\n",
    "\n",
    "#     if save_y:\n",
    "#         save_samples(results_dir, x1, epoch, 2, data_type, nrow=2, heatmap=True, cmap='jet', target_images=target)\n",
    "#     else:\n",
    "#         save_samples(results_dir, x1, epoch, 2, data_type, nrow=2, heatmap=True, cmap='jet')\n",
    "        \n",
    "        \n",
    "    return generated_x_all\n",
    "\n",
    "\n",
    "#sample_data(999, sample_loader, INN_network, cond_network, device, n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzaZuMkn0WZe",
    "outputId": "d8d4d304-c668-4149-c3ae-bf1358a0c6e0",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('\\nStart training\\n')\n",
    "\n",
    "# loss_train_all = []\n",
    "# loss_test_all = []\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95, verbose  =True)\n",
    "\n",
    "# if run_type == 'local' or run_type == 'work_station0' :\n",
    "#     no_epoch = 5\n",
    "#     save_int = 2\n",
    "# else:\n",
    "#     no_epoch = args.epochs\n",
    "#     save_int = 20\n",
    "\n",
    "# # no_epoch = 2\n",
    "# # save_int = 1\n",
    "# # no_epoch = 5\n",
    "# # save_int = 2\n",
    "# %matplotlib inline\n",
    "# # print(int(no_epoch/(save_int*5))+2)\n",
    "# input, target = next(iter(sample_loader))   \n",
    "\n",
    "# fig, axs = plt.subplots(int((5+no_epoch/save_int)/5)+1,5, figsize = (3*5, 3*(int(5+no_epoch/save_int)/5+1)))\n",
    "# #plt.figure(figsize = (2*int(no_epoch/(save_int*5))+4,5*2))\n",
    "# axs_no = 0\n",
    "# # axs[1][1].imshow(input[0],cmap = 'gray')\n",
    "# # axs[1][1].set_title('Actual')\n",
    "# axs[0][0].imshow(target[0][0], cmap = 'gray')\n",
    "# axs[0][0].set_title('Input-1')\n",
    "# axs[0][1].imshow(target[0][1],cmap = 'gray')\n",
    "# axs[0][1].set_title('Input-2')\n",
    "# axs[0][2].imshow(target[0][2],cmap = 'gray')\n",
    "# axs[0][2].set_title('Input-3')\n",
    "# axs[0][3].imshow(target[0][3],cmap = 'gray')\n",
    "# axs[0][3].set_title('Input-4')\n",
    "# axs[0][4].imshow(input[0],cmap = 'gray')\n",
    "# axs[0][4].set_title('Actual')\n",
    "# # axs[1][0].imshow(target[0][5],cmap = 'gray')\n",
    "# # axs[1][0].set_title('Input-6')\n",
    "# # axs[1][1].imshow(target[0][6],cmap = 'jet')\n",
    "# # axs[1][1].set_title('Input-7')\n",
    "# # axs[1][2].imshow(target[0][7],cmap = 'jet')\n",
    "# # axs[1][2].set_title('Input-8')\n",
    "# # axs[1][3].imshow(target[0][8],cmap = 'jet')\n",
    "# # axs[1][3].set_title('Input-9')\n",
    "# # axs[1][4].imshow(target[0][9],cmap = 'jet')\n",
    "# # axs[1][4].set_title('Input-10')\n",
    "# axs_no = axs_no + 6\n",
    "\n",
    "# from datetime import datetime\n",
    "# print(f'\\n Date (d/m/y): {datetime.now().strftime(\"%d/%m/%Y\")}, Time (H/M/S): {datetime.now().strftime(\"%H:%M:%S\")} \\n')\n",
    "\n",
    "# for epoch in range(1,no_epoch+1):\n",
    "#     loss_train = train(epoch, train_loader, INN_network, cond_network, device, optimizer)\n",
    "#     loss_train = np.mean(loss_train)\n",
    "#     loss_train_all.append(loss_train)\n",
    "#     with torch.no_grad():\n",
    "#         #sample_data(epoch, sample_loader, INN_network, cond_network, device, n_samples=1, save_y=False)\n",
    "#         #sample_data_new(epoch, sample_loader, INN_network, cond_network, device, n_samples=1, save_y=False)\n",
    "#         loss_test = test(epoch, test_loader, INN_network, cond_network, device)\n",
    "#         loss_test = np.mean(loss_test)\n",
    "#         loss_test_all.append(loss_test)\n",
    "\n",
    "#     print(f\"Epoch {epoch} - Train loss {loss_train:.3f} Test loss {loss_test:.3f}\")\n",
    "#     if epoch==1 or epoch % save_int == 0:\n",
    "#         axs_no +=1\n",
    "#         axs_no_row = int(axs_no/5)\n",
    "#         axs_no_col = axs_no - 5*int(axs_no/5)\n",
    "#         gen_x_all = sample_data_new(epoch, sample_loader, INN_network, cond_network, device, n_samples=1, save_y=False)\n",
    "        \n",
    "#         gen_x_mod = np.zeros((64,64))\n",
    "#         for i in range(64):\n",
    "#             for j in range(64):\n",
    "#                 if gen_x_all[1][i][j] > 0.6:\n",
    "#                     gen_x_mod[i,j] = 1\n",
    "#                 if gen_x_all[1][i][j] < 0.4:\n",
    "#                     gen_x_mod[i,j] = 0\n",
    "#                 if 0.4 <= gen_x_all[1][i][j] <= 0.6:\n",
    "#                     gen_x_mod[i,j] = gen_x_all[1][i][j]   \n",
    "#         axs[axs_no_row][axs_no_col].imshow(gen_x_mod.reshape(64,64),cmap = 'jet')\n",
    "#         axs[axs_no_row][axs_no_col].set_title(f'Gen_x_{epoch}')\n",
    "#         fig.suptitle(f'Epoch {epoch},Version: {ver}, Input:{input_size}x{input_size}, Output: {output_size}x{output_size}',fontsize = 12)\n",
    "#         plt.savefig(f'Generated_x_epoch_{epoch}.png')\n",
    "#         if epoch !=1:\n",
    "#             scheduler.step()\n",
    "#         if run_type == 'work_station1' and epoch == no_epoch:\n",
    "#             gen_model_path = results_dir + f\"/generative_network_{ver}_ep{epoch}.pt\"\n",
    "#             cond_model_path = results_dir + f\"/conditioning_network_{ver}_ep{epoch}.pt\"\n",
    "#             print(gen_model_path)\n",
    "#             torch.save(INN_network.state_dict(), gen_model_path)\n",
    "#             torch.save(cond_network.state_dict(), cond_model_path)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# gen_model_path = results_dir + \"/generative_network.pt\"\n",
    "# cond_model_path = results_dir + \"/conditioning_network.pt\"\n",
    "\n",
    "# if run_type == 'colab':\n",
    "#     torch.save(INN_network, gen_model_path)\n",
    "#     torch.save(cond_network, cond_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_network.load_state_dict(torch.load(\"'E:\\\\INN-TO\\\\Final-V8_10_11_ReRun_4_Imgs\\\\two_dim\\\\results\\\\generative_network_V8_10_11_ReRun_4_Imgs_ep200.pt\"))\n",
    "cond_network.load_state_dict(torch.load(\"'E:\\\\INN-TO\\\\Final-V8_10_11_ReRun_4_Imgs\\\\two_dim\\\\results\\\\conditioning_network_V8_10_11_ReRun_4_Imgs_ep200.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_x_all = sample_data_new(100, sample_loader, INN_network, cond_network, device, n_samples=1, save_y=False)\n",
    "gen_x_mod_all = np.zeros((1,64,64))\n",
    "for k in range(1):\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            if gen_x_all[k][i][j] > 0.6:\n",
    "                gen_x_mod_all[k,i,j] = 1\n",
    "            if gen_x_all[k][i][j] < 0.4:\n",
    "                gen_x_mod_all[k,i,j] = 0\n",
    "            if 0.4 <= gen_x_all[k][i][j] <= 0.6:\n",
    "                gen_x_mod_all[k,i,j] = gen_x_all[k][i][j]\n",
    "    plt.imsave(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_HardTO.png\", gen_x_mod_all[k], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "for k in range(1):\n",
    "    scipy.io.savemat(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_HardTO.mat\", mdict = {'arr':gen_x_mod_all[k]})\n",
    "# plt.imsave(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_HardTO.png\", gen_x_mod_all[k], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "nelx = 64\n",
    "nely = 64\n",
    "rmin = 3\n",
    "iH = np.ones(nelx*nely*(2*(math.ceil(rmin)-1)+1)**2).astype(int)\n",
    "jH = np.ones(iH.shape).astype(int)\n",
    "sH = np.zeros(iH.shape)\n",
    "k = 0\n",
    "for i1 in range(1,nelx+1):\n",
    "    for j1 in range(1,nely+1):\n",
    "        e1 = (i1-1)*nely + j1\n",
    "        for i2 in range(max(i1-(math.ceil(rmin)-1),1),min(i1+(math.ceil(rmin)-1),nelx)+1):\n",
    "            for j2 in range(max(j1-(math.ceil(rmin)-1),1),min(j1+(math.ceil(rmin)-1),nely)+1):\n",
    "                e2 = (i2-1)*nely+j2 \n",
    "#                 print(f' i1 = {i1}, j1 = {j1}, i2 = {i2}, j2 = {j2}, e1 = {e1}, e2 = {e2}' )\n",
    "#                 print(f'i2 range = {max(i1-(math.ceil(rmin)-1),1)} to {min(i1+(math.ceil(rmin)-1),nelx)}')\n",
    "#                 print(f'j2 range =  {max(j1-(math.ceil(rmin)-1),1)} to {min(j1+(math.ceil(rmin)-1),nelx)}' )\n",
    "                k = k+1\n",
    "#                 print(f'k = {k}')\n",
    "                iH[k-1] = e1\n",
    "                jH[k-1] = e2\n",
    "                sH[k-1] = max(0,rmin-math.sqrt((i1-i2)**2+(j1-j2)**2))\n",
    "\n",
    "H = scipy.sparse.csc_matrix((sH,(iH-1,jH-1)))\n",
    "Hs = np.sum(H, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_x_mod_TO = np.zeros((1,64,64))\n",
    "for k in range(1):\n",
    "    row = gen_x_all[k].flatten()[np.newaxis]\n",
    "    gen_x_mod_TO[k] = (H*(row.T)/Hs).reshape(64,64)\n",
    "    gen_x_mod_TO[k] = np.squeeze(np.asarray(gen_x_mod_TO[k]))\n",
    "    plt.imsave(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_Only_TOF.png\", gen_x_mod_TO[k], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "for k in range(1):\n",
    "    scipy.io.savemat(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_TOPO.mat\", mdict = {'arr':gen_x_mod_TO[k]})\n",
    "# plt.imsave(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_HardTO.png\", gen_x_mod_all[k], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_x_all = sample_data_new(100, sample_loader, INN_network, cond_network, device, n_samples=1, save_y=False)\n",
    "gen_x_mod_both = np.zeros((1,64,64))\n",
    "for k in range(1):\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            if gen_x_mod_TO[k][i][j] > 0.6:\n",
    "                gen_x_mod_both[k,i,j] = 1\n",
    "            if gen_x_mod_TO[k][i][j] < 0.4:\n",
    "                gen_x_mod_both[k,i,j] = 0\n",
    "            if 0.4 <= gen_x_mod_TO[k][i][j] <= 0.6:\n",
    "                gen_x_mod_both[k,i,j] = gen_x_mod_TO[k][i][j]\n",
    "    plt.imsave(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_Both_TO_HTH.png\", gen_x_mod_both[k], cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_1_Both_TO_HTH.txt\",gen_x_mod_both.reshape(64,64), fmt ='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "for k in range(1):\n",
    "    scipy.io.savemat(results_dir + \"\\\\\" + \"generated_samples\\\\\" +  f\"Generated_Sample_{k+1}_Both_TO_HTH.mat\", mdict = {'arr':gen_x_mod_both[k]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
